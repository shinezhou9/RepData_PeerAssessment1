1 / outer(i - 1, i, "+")
}
x <- hilbert(1000)
system.time(svd(x))
?params
?optim
?optimize
make.NeglogLik <- function(data, fixed = c(FALSE, FALSE)) {
param <- fixed
function(p) {
patams[!fixed] <- p
mu <- params[1]
sima <- params[2]
a <- -0.5*length(data)*log(2*pi*sigma^2)
b <- -0.5*sum(data - mu)^2 / (sigma^2)
-(a+b)
}
}
set.seed(1); normals <- rnorm(100, 1, 2)
nLL <- make.NegLogLik(normals)
nLL <- make.NeglogLik(normals)
nLL
p
optim(c(mu = 0, sigma = 1), nLL)$par
make.NeglogLik <- function(data, fixed = c(FALSE, FALSE)) {
param <- fixed
function(p) {
params[!fixed] <- p
mu <- params[1]
sima <- params[2]
a <- -0.5*length(data)*log(2*pi*sigma^2)
b <- -0.5*sum(data - mu)^2 / (sigma^2)
-(a+b)
}
}
optim(c(mu = 0, sigma = 1), nLL)$par
make.NeglogLik <- function(data, fixed = c(FALSE, FALSE)) {
param <- fixed
function(p) {
params[!fixed] <- p
mu <- params[1]
sima <- params[2]
a <- -0.5*length(data)*log(2*pi*sigma^2)
b <- -0.5*sum(data - mu)^2 / (sigma^2)
-(a+b)
}
}
optim(c(mu = 0, sigma = 1), nLL)$par
make.NeglogLik <- function(data, fixed = c(FALSE, FALSE)) {
param <- fixed
function(p) {
params[!fixed] <- p
mu <- params[1]
sima <- params[2]
a <- -0.5*length(data)*log(2*pi*sigma^2)
b <- -0.5*sum(data - mu)^2 / (sigma^2)
-(a+b)
}
}
make.NeglogLik <- function(data, fixed = c(FALSE, FALSE)) {
param <- fixed
function(p) {
params[!fixed] <- p
mu <- params[1]
sima <- params[2]
a <- -0.5*length(data)*log(2*pi*sigma^2)
b <- -0.5*sum(data - mu)^2 / (sigma^2)
-(a+b)
}
}
set.seed(1); normals <- rnorm(100, 1, 2)
nLL <- make.NeglogLik(normals)
nLL
optim(c(mu = 0, sigma = 1), nLL)$par
make.NeglogLik <- function(data, fixed = c(FALSE, FALSE)) {
params <- fixed
function(p) {
params[!fixed] <- p
mu <- params[1]
sima <- params[2]
a <- -0.5*length(data)*log(2*pi*sigma^2)
b <- -0.5*sum(data - mu)^2 / (sigma^2)
-(a+b)
}
}
set.seed(1); normals <- rnorm(100, 1, 2)
nLL <- make.NeglogLik(normals)
nLL
optim(c(mu = 0, sigma = 1), nLL)$par
make.NeglogLik <- function(data, fixed = c(FALSE, FALSE)) {
params <- fixed
function(p) {
params[!fixed] <- p
mu <- params[1]
sigma <- params[2]
a <- -0.5*length(data)*log(2*pi*sigma^2)
b <- -0.5*sum(data - mu)^2 / (sigma^2)
-(a+b)
}
}
set.seed(1); normals <- rnorm(100, 1, 2)
nLL <- make.NeglogLik(normals)
nLL
optim(c(mu = 0, sigma = 1), nLL)$par
?function
?function
?function()
?optim
?optimize
?optim
v <- rnorm(100, 1, 2)
length(v)
optim(c(mu = 2, sigma = 3), nLL)$par
optim(c(mu = 10, sigma = 10), nLL)$par
?lm
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
set.seed(1)
rpois(5, 2)
boxplot
?boxplot
?abline
?lwd
?barplot
?table
data.frame(x = rep(c("a", "b", "c"), each = 3, y = rnorm(10)))
data.frame(x = rep(c("a", "b", "c"), each = 3), y = rnorm(10))
data.frame(x = rep(c("a", "b", "c"), each = 3), y = rnorm(9))
frame <- data.frame(x = rep(c("a", "b", "c"), each = 3), y = rnorm(9))
h <- frame$y
h
class(h)
table(y)
table(h)
?boxplot
?par
?hist
?mflow
?par
?boxplot
?with
?plot
library(lattice)
?xyplot
?plot
?transform
library(datasets)
head(airquality)
airquality <- transform(airquality, Month = factor(Month))
head(airquality)
class(airquality$Month)
rm(airquality)
library(datasets)
head(airquality)
class(airquality$Month)
?boxplot
boxplot(Ozone ~ Month, airquality, xlab = "Month", ylab = "Ozone(ppb")
?line
?abline
>coef
?coef
?title
?plot
?legend
?lm
?oma
?par
mtext()
?mtext
example(points)
?points
dat <- read.table(pipe('grep "^[1-2]/2/2007" "household_power_consumption.txt"'), header=F, sep=';', na.strings = "?")
colnames(dat) <-names(read.table('household_power_consumption.txt', header=TRUE,sep=";",nrows=1))
dat$Date <- as.Date(dat$Date, format = "%d/%m/%Y")
dat$DateTime <- paste(dat$Date, dat$Time)
dat$DateTime <- as.POSIXlt(dat$DateTime)
topY <- max(dat$Sub_metering_1, dat$Sub_metering_2, dat$Sub_metering_3)
lowY <- min(dat$Sub_metering_1, dat$Sub_metering_2, dat$Sub_metering_3)
plot(dat$DateTime, dat$Sub_metering_1, type = "l", col = "black", ylim = c(lowY, topY),xlab = " ", ylab = "Energy sub metering")
lines(dat$DateTime, dat$Sub_metering_2, col = "red")
lines(dat$DateTime, dat$Sub_metering_3, col = "blue")
legend("topright",col = c("black", "red", "blue"),  lty = "solid", legend = c("Sub_metering_1", "Sub_metering_2", "Sub_metering_3"))
dev.copy(png, file = "plot3.png", width=480, height=480, units = "px")
dev.off
?sum
?reformula
?reformulate
?glm
>predict
?predict
?table
install.packages("ProjectTemplate")
library(ProjectTemplate)
?ProjectTemplate
First Line Second Line
First Line Second Line
### Header 3
This is a blockquote
Theis is the second paragraph in the blockquote
##This is an H2 in a blockquote
### Header 3
>This is a blockquote
>Theis is the second paragraph in the blockquote
>##This is an H2 in a blockquote
* Cand
* Gum
* Booze
### Header 3
* Cand
* Gum
* Booze
### Header 3
## Heading 2
?plot
?text
?lines
?choose
?pbinom
?choose
?dbinom
?Seq
?seq
seq(0, 1, lengh = 1000)
seq(0, 1, length = 1000)
?text
?abline
dnorm()
?dnorm
dnorm(0.2)
dnorm(3)
dnorm(-3)
dnorm(1)
dnorm(0)
?qnorm
dnorm(1.645)
pnorm(1.645)
qnorm(0.95)
pnorm(2, lower.tail = FALSE)
pnorm(2)
pbinom(3, size = 5, prob = .5, lower.tail = False)
pbinom(3, size = 5, prob = .5, lower.tail = FALSE)
qnorm(.95, mean = 1100, sd = 75)
qnorm(.95, mean = 1100, sd = 75/11)
ppois(10, lamda = 5*3)
?ppois
ppois(10, lambda = 5*3)
(0.75*0.3)/((0.75*0.3)+(0.75*0.7))
pnorm(70, mu = 80, sd = 10)
pnorm(70, mu = 80, sd = 10)
?pnorm
pnorm(70, meam = 80, sd = 10)
pnorm(70, mean = 80, sd = 10)
pnorm(16, mean = 15, sd = 10) - pnorm(14, mean = 15, sd = 10)
mean(1:10)
std(1:10)
sd(1:10)
mean(c(1, 3, 5, 7, 9))
sd(c(1, 3, 5, 7, 9))
?qnorm
qnorm(.95, mean = 1100, sd = 99/100*75 )
?pnorm
pnorm(16, mean = 15, sd =10)
pnorm(14, mean = 14, sd = 10)
pnorm(16, mean = 15, sd = 1) - pnorm(14, mean = 15, sd = 1)
qnorm(.95, mean = 1100, 75/100)
?round
?poisson.test
x <- 5; t <- 94.32; lambda <- x/t
poisson.test(x, T = 94.34)$conf
?sqrt
qchisq
?qchiq
?qchisq
qnorm(.95, mean = 1100, sd = 75)
qnorm(.95, mean = 1100, sd = 75/10)
sqrt(1/(1.2*1000000))
sqrt(1/12*100000)
sqrt(1/(12*100000))
sqrt(1/(12*100))
0.75*0.3/(0.75*0.3+(0.48*0.7))
library(data.table)
DT <- data.table(x = rnorm(9), y = rep(c("a", "b", "c"), each = 3), z = rnorm(9))
head(DT)
install.packages("RMySQL")
mysql --user=genome --host=genome-mysql.cse.ucsc.edu -A
library(RMySQL)
ucscDb <- dbConnect(MySQL(), user = "genome", host = "genome-mysql, cse.ucsc.edu")
ucscDb <- dbConnect(MySQL(), user = "genome", host = "genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucscDb, "show databases;"); dbDisconnect(ucscDb)
?dbGetQuery
result
?dbDisconnect
?dbGetQuery
?dbListTables
?dbSendQuery
?db
?quantile
?fetch
?dbClearResult
?fetch
?dim
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(rhdf5)
?seq
?attr
?h5write
?seq
df <- data.frame(1L:5L, seq(0,1.length.out = 5), c("ab","cde","fghi","a","s"), stringAsFactors=FALSE)
df <- data.frame(1L:5L, seq(0,1,length.out = 5), c("ab","cde","fghi","a","s"), stringAsFactors=FALSE)
head(df)
?list
library(XML)
install.packages("httr")
library(httr)
?get
?handle
google <- handle("http://google.com")
pg1 <- GET(handle = google, path = "/")
?GET
pg1
?require
require(ggplot)
requiire(ggplot2)
require(ggplot2)
install.packages("ggplot2")
require(ggplot2)
?aes
?oauth
?oauth_app
?sign_oauth1.0
?GET
https://api.twitter.com/1.1/search/tweets.json
sjdk
dhls
myapp <- oauth_app("twitter". key = "PIjF9J3TB1HzDd0IPoIEabWA6", secret = "W7PXjmxdiHAUEq8XutO7XbOIWi6THZUzkTvp90mkh8zj9TJMnF")
sig <- sign_oauth1.0(myapp, token = "916160125-uutb8ijeVFcDuWaGLObTVrYaoWyq5jFW23Z5Te7j", token_secret = "MZIInQNEtOjtLBwMZcpCGKCRBF8iJnGjwmU1NG1bVboLO")
homeTL = GET("https://api.twitter.com/1.1/search/tweets.json", sig)
library(httr)
myapp <- oauth_app("twitter". key = "PIjF9J3TB1HzDd0IPoIEabWA6", secret = "W7PXjmxdiHAUEq8XutO7XbOIWi6THZUzkTvp90mkh8zj9TJMnF")
sig <- sign_oauth1.0(myapp, token = "916160125-uutb8ijeVFcDuWaGLObTVrYaoWyq5jFW23Z5Te7j", token_secret = "MZIInQNEtOjtLBwMZcpCGKCRBF8iJnGjwmU1NG1bVboLO")
homeTL = GET("https://api.twitter.com/1.1/search/tweets.json", sig)
myapp <- oauth_app("twitter", key = "PIjF9J3TB1HzDd0IPoIEabWA6", secret = "W7PXjmxdiHAUEq8XutO7XbOIWi6THZUzkTvp90mkh8zj9TJMnF")
sig <- sign_oauth1.0(myapp, token = "916160125-uutb8ijeVFcDuWaGLObTVrYaoWyq5jFW23Z5Te7j", token_secret = "MZIInQNEtOjtLBwMZcpCGKCRBF8iJnGjwmU1NG1bVboLO")
homeTL = GET("https://api.twitter.com/1.1/search/tweets.json", sig)
head(homeTL)
?jsonlite
?fromJSON
??fromJSON
library(jsonlite)
?fromJSON
?connections
setwd("~/Desktop/Get & Clean Data/assignment/UCI HAR Dataset")
#read the data with read.table()
sub_train <- read.table("./train/subject_train.txt")
X_train <- read.table("./train/X_train.txt")
y_train <- read.table("./train/y_train.txt")
sub_test <- read.table("./test/subject_test.txt")
X_test <- read.table("./test/X_test.txt")
y_test <- read.table("./test/y_test.txt")
act_labels<- read.table("./activity_labels.txt", stringsAsFactors = FALSE)
#Step1. Merges the training and the test sets to create one data set.
#using cbind() to create dataframe "train" which including the "subject_train", "X_train" and "y_train" data, the same applys to dataframe "test"
train <- cbind(X_train, sub_train, y_train)
test <- cbind(X_test, sub_test, y_test)
#using rbind() to merge the two dataframes "train" and "test" into one dataframe: "data_raw"
data_raw <- rbind(train, test)
#clean up the data with gsub(). There are characters in the names "-" or "," that will cause problems in analysis in R, and expand t and f to time and freq(frequency), and correct "BodyBody" which seems to be a engine mistake on the people who prepared the data to "Body"
fet <- read.table("./features.txt")
fet$V2 <- gsub("\\(\\)", "", fet$V2)
#fet$V2 <- gsub("[[:punct:]]", "_", fet$V2)
fet$V2 <- gsub("-", "_", fet$V2)
fet$V2 <- gsub("tBody", "time_Body", fet$V2)
fet$V2 <- gsub("tGravityAcc", "time_Gravity", fet$V2)
fet$V2 <- gsub("fBody", "freq_Body", fet$V2)
fet$V2 <- gsub("fBody", "freq_Body", fet$V2)
#giving the colume names to "data_raw", the first 561 columes'names come from "features", the last two columes are "data_type"(train_data or test_data) and "activity"
names(data_raw) <- c(fet[,2], "sub", "act_labels")
#step2. Extracts only the measurements on the mean and standard deviation for each measurement.
#identifying the columns by grep(), and subseting the columns and the "sub" and "act_labels" columns
m <- grep("mean", fet$V2)
g <- grep("std", fet$V2)
data1 <- data_raw[,c(m,g, 562, 563)]
#step3. Uses descriptive activity names to name the activities in the data set.
#change the value in last column(represent activity labels) to factors, and use the names in "act_label" dataframe as the level of the factors. 81 is the index of the last column in "data1"
data1$act_names <- as.factor(data1$act_labels)
levels(data1$act_names) <- act_labels[,2]
#step4 Appropriately labels the data set with descriptive variable names.
#did that in step1
#step5. Using aggregate() to creates a second, independent tidy data set "data_clean" with the average of each variable for each activity and each subject.
data_clean <- aggregate(data1[,1:79], by = list(activity = data1$act_names, subject=data1$sub), FUN = mean)
head(data_clean)
dim(data_clean)
names(data_clean)
?write.csv
write.csv(data_clean, file="tidy_data.csv")
?aggregate
?sprtf
?sprintf
setwd("~/Desktop/Reproducible Research/RepData_PeerAssessment1")
source('~/.active-rstudio-document', echo=TRUE)
data <- read.csv("activity.csv", header = TRUE, sep = ",")
data$date_revised <- as.Date(data$date)
data$interval_revised <- sprintf("%04d", data$interval)
data$interval_time <- strptime(data$interval_revised, format = "%H%M")
s_date <- split(data, data$date_revised)
total_steps <- sapply(s_date, function(x) sum(x$steps, na.rm = TRUE))
head(total_steps)
mean_steps <- mean(total_steps, na.rm = TRUE)
mean_steps
total_steps <- sapply(s_date, function(x) sum(x$steps))
head(total_steps)
mean_steps <- mean(total_steps, na.rm = TRUE)
median_steps <- median(total_steps, na.rm = TRUE)
mean_steps
median_steps
?qt
?dpois
lines
?lines
?rep
r <- rep(1/8, 2)
r
r1 <- rep(1/8)
r1
lambda <- seq(0, 0.2, length = 1000)likelihood <- dpois(5, 94 * lambda)/dpois(5, 5)plot(lambda, likelihood, frame = FALSE, lwd = 3, type = "l", xlab = expression(lambda))lines(rep(5/94, 2), 0:1, col = "red", lwd = 3)lines(range(lambda[likelihood > 1/16]), rep(1/16, 2), lwd = 2)lines(range(lambda[likelihood > 1/8]), rep(1/8, 2), lwd = 2)
lambda <- seq(0, 0.2, length = 1000)likelihood <- dpois(5, 94 * lambda)/dpois(5, 5)plot(lambda, likelihood, frame = FALSE, lwd = 3, type = "l", xlab = expression(lambda))lines(rep(5/94, 2), 0:1, col = "red", lwd = 3)lines(range(lambda[likelihood > 1/16]), rep(1/16, 2), lwd = 2)lines(range(lambda[likelihood > 1/8]), rep(1/8, 2), lwd = 2)
lambda <- seq(0, 0.2, length = 1000)likelihood <- dpois(5, 94 * lambda)/dpois(5, 5)plot(lambda, likelihood, frame = FALSE, lwd = 3, type = "l", xlab = expression(lambda))lines(rep(5/94, 2), 0:1, col = "red", lwd = 3)lines(range(lambda[likelihood > 1/16]), rep(1/16, 2), lwd = 2)lines(range(lambda[likelihood > 1/8]), rep(1/8, 2), lwd = 2)
lambda <- seq(0, 0.2, length = 1000)
likelihood <- dpois(5, 94 * lambda)/dpois(5, 5)
plot(lambda, likelihood, frame = FALSE, lwd = 3, type = "l", xlab = expression(lambda))
lines(rep(5/94, 2), 0:1, col = "red", lwd = 3)
lines(range(lambda[likelihood > 1/16]), rep(1/16, 2), lwd = 2)
lines(range(lambda[likelihood > 1/8]), rep(1/8), lwd = 2)
range(lambda[likelihood > 1/8])
slider
library(manipulate)
?slider
?manipulate
?plot
?dbinon
?binom
?dbinom
dbinon(3, 4, 3/4)
dbinom(3, 4, 3/4)
pbinom(3, 4, 3/4)
?dbeta
library(binom)
install.packages("binom")
?binom.beyes
?binom.bayes
?library(binom)
?binom.bayes
?binom
??binom.bayes
library(binom)
?binom.bayes
binom.bayes(13, 20, type = "highest")
0.65*20/21 + 0.5*(1/21)
>lines
?lines
?t.test
?qt
1100 +c(-1, 1)*qnorm(.975, df = 8)*30/sqrt(9)
1100 +c(-1, 1)*qt(.975, df = 8)*30/sqrt(9)
-6/qt(.975, df = 8)
6/qt(.975, df = 8)
x1 <- 3; x2 <- 5
v1 <- 0.6; v2 <= 0.68
n1 <- 10; n2 <- 10
sp <- sqrt(((n1-1)*v1 + (n2-1)*v2)/(n1 + n2 -2))
md <- x1 - x2
semd <- sp * sqrt(1/n1 + 1/ n2)
md + c(-1,2)*qt(.975, n1 + n2 -2)*semd
x1 <- 3; x2 <- 5
v1 <- 0.6; v2 <- 0.68
n1 <- 10; n2 <- 10
sp <- sqrt(((n1-1)*v1 + (n2-1)*v2)/(n1 + n2 -2))
md <- x1 - x2
semd <- sp * sqrt(1/n1 + 1/ n2)
md + c(-1,2)*qt(.975, n1 + n2 -2)*semd
x1 <- 3; x2 <- 5
v1 <- 0.6; v2 <- 0.68
n1 <- 10; n2 <- 10
sp <- sqrt(((n1-1)*v1 + (n2-1)*v2)/(n1 + n2 -2))
md <- x1 - x2
semd <- sp * sqrt(1/n1 + 1/ n2)
md + c(-1,1)*qt(.975, n1 + n2 -2)*semd
x1 <- 3; x2 <- 5
v1 <- 0.6; v2 <- 0.68
n1 <- 10; n2 <- 10
sp <- sqrt(((n1-1)*v1 + (n2-1)*v2)/(n1 + n2 -2))
md <- x1 - x2
semd <- sp * sqrt(1/n1 + 1/ n2)
md + c(-1,1)*qt(.95, n1 + n2 -2)*semd
x1 <- -3; x2 <- 1
v1 <- 1.5; v2 <- 1.8
n1 <- 9; n2 <- 9
sp <- sqrt(((n1-1)*v1 + (n2-1)*v2)/(n1 + n2 -2))
md <- x1 - x2
semd <- sp * sqrt(1/n1 + 1/ n2)
md + c(-1,1)*qt(.95, n1 + n2 -2)*semd
x1 <- -3; x2 <- 1
s1 <- 1.5; s2 <- 1.8
n1 <- 9; n2 <- 9
sp <- sqrt(((n1-1)*s1^2 + (n2-1)*s2^2)/(n1 + n2 -2))
md <- x1 - x2
semd <- sp * sqrt(1/n1 + 1/ n2)
md + c(-1,1)*qt(.95, n1 + n2 -2)*semd
library(binom)
